# Projeto de ETL de Dados da F√≥rmula 1

## Vis√£o Geral

Este projeto implementa um pipeline de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) para processar dados de corridas de F√≥rmula 1. Os dados s√£o extra√≠dos de arquivos CSV, transformados usando a biblioteca Pandas em Python e, em seguida, carregados em um banco de dados PostgreSQL. O ambiente do projeto √© totalmente containerizado usando Docker e Docker Compose, facilitando a configura√ß√£o e a execu√ß√£o.

## ‚öôÔ∏è Funcionalidades

- **Extra√ß√£o**: L√™ dados de construtores, pilotos, corridas e resultados a partir de arquivos CSV.
- **Transforma√ß√£o**: Realiza a limpeza e o pr√©-processamento dos dados, como a convers√£o de tipos de dados, tratamento de valores ausentes e a cria√ß√£o de novas colunas para an√°lise.
- **Carga**: Insere os dados transformados em tabelas de um banco de dados PostgreSQL.
- **Configura√ß√£o do Banco de Dados**: Cria automaticamente as tabelas e views necess√°rias para a an√°lise dos dados.
- **An√°lise**: Fornece queries SQL prontas para an√°lises, como o desempenho em corridas e as voltas mais r√°pidas.
- **Ambiente Dockerizado**: Utiliza Docker Compose para orquestrar os servi√ßos da aplica√ß√£o (aplica√ß√£o Python e banco de dados PostgreSQL), garantindo um ambiente de desenvolvimento e produ√ß√£o consistente e de f√°cil configura√ß√£o.

## üõ†  Tecnologias Utilizadas

- **Linguagem de Programa√ß√£o**: Python 3.12
- **Banco de Dados**: PostgreSQL
- **Bibliotecas Python**:
  - `pandas`: Para manipula√ß√£o e an√°lise de dados.
  - `SQLAlchemy`: Para o mapeamento objeto-relacional (ORM) e intera√ß√£o com o banco de dados.
  - `psycopg2-binary`: Driver PostgreSQL para Python.
  - `python-dotenv`: Para gerenciamento de vari√°veis de ambiente.
  - `python-slugify`, `unidecode`: Para manipula√ß√£o de strings.
- **Containeriza√ß√£o**: Docker & Docker Compose

## üöÄ Estrutura do Projeto

.
![image](https://github.com/user-attachments/assets/2fb2897c-3b2b-4073-b195-08e5583bcd27)


## Como Executar o Projeto

### Pr√©-requisitos

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### Configura√ß√£o

1.  **Clone o reposit√≥rio** (se aplic√°vel):
    ```bash
    git clone <url-do-seu-repositorio>
    cd <nome-do-repositorio>
    ```

2.  **Vari√°veis de Ambiente**:
    Crie um arquivo `.env` na raiz do projeto, seguindo o exemplo do arquivo `.env_example` (n√£o fornecido, mas inferido a partir do c√≥digo). Este arquivo deve conter as credenciais e configura√ß√µes do banco de dados.
    ```env
    POSTGRES_USER=admin
    POSTGRES_PASSWORD=admin
    POSTGRES_DB=formula_db
    DB_HOST=localhost #com docker ficaria local.docker.internal
    DB_PORT=5432
    ```

### Execu√ß√£o

1.  **Construir e iniciar os containers**:
    Na raiz do projeto, execute o seguinte comando para construir as imagens e iniciar os containers da aplica√ß√£o Python e do banco de dados PostgreSQL em segundo plano.

    ```bash
    docker-compose up --build -d
    ```

2.  **Verificar a Execu√ß√£o**:
    O script `main.py` ser√° executado automaticamente. Ele ir√°:
    - Configurar o banco de dados (`setup_db.py`).
    - Extrair os dados dos arquivos CSV (`extraction.py`).
    - Transformar os dados (`transformation.py`).
    - Carregar os dados para o PostgreSQL (`loading.py`).

    Voc√™ pode verificar os logs para acompanhar o processo:
    ```bash
    docker-compose logs -f python-app
    ```

3.  **Acessar o Banco de Dados**:
    Ap√≥s a conclus√£o do pipeline, voc√™ pode se conectar ao banco de dados PostgreSQL para executar as queries de an√°lise localizadas em `scripts_db/`.

## Descri√ß√£o dos Scripts

- **`main.py`**: Orquestra todo o fluxo do pipeline ETL, chamando as fun√ß√µes de extra√ß√£o, transforma√ß√£o e carga em sequ√™ncia.
- **`src/setup_db.py`**: Conecta-se ao banco de dados e executa os scripts `create_table.sql` e `create_views.sql` para preparar o esquema do banco.
- **`src/extraction.py`**: Cont√©m a l√≥gica para ler os arquivos CSV do diret√≥rio `extraction/` e carreg√°-los em DataFrames do Pandas.
- **`src/transformation.py`**: Respons√°vel por limpar, transformar e enriquecer os dados brutos para prepar√°-los para a an√°lise.
- **`src/loading.py`**: Carrega os DataFrames transformados nas tabelas correspondentes do banco de dados PostgreSQL.
- **`scripts_db/`**:
- **`create_table.sql`**: Define a estrutura das tabelas que armazenar√£o os dados.
- **`create_views.sql`**: Cria views SQL para simplificar consultas de an√°lise complexas.
- **`query_*.sql`**: Cont√©m exemplos de consultas para extrair insights dos dados, como identificar as voltas mais r√°pidas.


## Autor
- **Alyff antonio**
